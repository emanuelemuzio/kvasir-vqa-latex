@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{xiao2023florence2advancingunifiedrepresentation,
      title={Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks}, 
      author={Bin Xiao and Haiping Wu and Weijian Xu and Xiyang Dai and Houdong Hu and Yumao Lu and Michael Zeng and Ce Liu and Lu Yuan},
      year={2023},
      eprint={2311.06242},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.06242}, 
}

@article{article,
author = {Lavie, Alon and Agarwal, Abhaya},
year = {2007},
month = {07},
pages = {228-231},
title = {METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments}
}

@misc{vedantam2015ciderconsensusbasedimagedescription,
      title={CIDEr: Consensus-based Image Description Evaluation}, 
      author={Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
      year={2015},
      eprint={1411.5726},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1411.5726}, 
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}

@inproceedings{10.3115/1073083.1073135,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: a method for automatic evaluation of machine translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
abstract = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}

@misc{li2022blipbootstrappinglanguageimagepretraining,
      title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}, 
      author={Junnan Li and Dongxu Li and Caiming Xiong and Steven Hoi},
      year={2022},
      eprint={2201.12086},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.12086}, 
}

@misc{liu2023visualinstructiontuning,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.08485}, 
}

@misc{li2023llavamedtraininglargelanguageandvision,
      title={LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day}, 
      author={Chunyuan Li and Cliff Wong and Sheng Zhang and Naoto Usuyama and Haotian Liu and Jianwei Yang and Tristan Naumann and Hoifung Poon and Jianfeng Gao},
      year={2023},
      eprint={2306.00890},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.00890}, 
}

@misc{wang2022gitgenerativeimagetotexttransformer,
      title={GIT: A Generative Image-to-text Transformer for Vision and Language}, 
      author={Jianfeng Wang and Zhengyuan Yang and Xiaowei Hu and Linjie Li and Kevin Lin and Zhe Gan and Zicheng Liu and Ce Liu and Lijuan Wang},
      year={2022},
      eprint={2205.14100},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2205.14100}, 
}

@article{DBLP:journals/corr/abs-2201-12086,
  author       = {Junnan Li and
                  Dongxu Li and
                  Caiming Xiong and
                  Steven C. H. Hoi},
  title        = {{BLIP:} Bootstrapping Language-Image Pre-training for Unified Vision-Language
                  Understanding and Generation},
  journal      = {CoRR},
  volume       = {abs/2201.12086},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.12086},
  eprinttype    = {arXiv},
  eprint       = {2201.12086},
  timestamp    = {Wed, 02 Feb 2022 15:00:01 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-12086.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@InProceedings{10.1007/978-3-540-76298-0_52,
author="Auer, S{\"o}ren
and Bizer, Christian
and Kobilarov, Georgi
and Lehmann, Jens
and Cyganiak, Richard
and Ives, Zachary",
editor="Aberer, Karl
and Choi, Key-Sun
and Noy, Natasha
and Allemang, Dean
and Lee, Kyung-Il
and Nixon, Lyndon
and Golbeck, Jennifer
and Mika, Peter
and Maynard, Diana
and Mizoguchi, Riichiro
and Schreiber, Guus
and Cudr{\'e}-Mauroux, Philippe",
title="DBpedia: A Nucleus for a Web of Open Data",
booktitle="The Semantic Web",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="722--735",
abstract="DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.",
isbn="978-3-540-76298-0"
}

@inproceedings{2023GPT4VisionSC,
  title={GPT-4V(ision) System Card},
  author={},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263218031}
}

@article{jaech2024openai,
  title={OpenAI o1 System Card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@misc{awal2024investigatingpromptingtechniqueszero,
      title={Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering}, 
      author={Rabiul Awal and Le Zhang and Aishwarya Agrawal},
      year={2024},
      eprint={2306.09996},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.09996}, 
}

@misc{lu2022learnexplainmultimodalreasoning,
      title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering}, 
      author={Pan Lu and Swaroop Mishra and Tony Xia and Liang Qiu and Kai-Wei Chang and Song-Chun Zhu and Oyvind Tafjord and Peter Clark and Ashwin Kalyan},
      year={2022},
      eprint={2209.09513},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.09513}, 
}

@misc{he2020pathvqa30000questionsmedical,
      title={PathVQA: 30000+ Questions for Medical Visual Question Answering}, 
      author={Xuehai He and Yichen Zhang and Luntian Mou and Eric Xing and Pengtao Xie},
      year={2020},
      eprint={2003.10286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2003.10286}, 
}

@misc{liang2021graghvqalanguageguidedgraphneural,
      title={GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual Question Answering}, 
      author={Weixin Liang and Yanhao Jiang and Zixuan Liu},
      year={2021},
      eprint={2104.10283},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.10283}, 
}

@misc{lin2015microsoftcococommonobjects,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1405.0312}, 
}

@article{DBLP:journals/corr/GoyalKSBP16,
  author       = {Yash Goyal and
                  Tejas Khot and
                  Douglas Summers{-}Stay and
                  Dhruv Batra and
                  Devi Parikh},
  title        = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding
                  in Visual Question Answering},
  journal      = {CoRR},
  volume       = {abs/1612.00837},
  year         = {2016},
  url          = {http://arxiv.org/abs/1612.00837},
  eprinttype    = {arXiv},
  eprint       = {1612.00837},
  timestamp    = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/GoyalKSBP16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{kim2021viltvisionandlanguagetransformerconvolution,
      title={ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision}, 
      author={Wonjae Kim and Bokyung Son and Ildoo Kim},
      year={2021},
      eprint={2102.03334},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2102.03334}, 
}

@misc{redmon2016lookonceunifiedrealtime,
      title={You Only Look Once: Unified, Real-Time Object Detection}, 
      author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
      year={2016},
      eprint={1506.02640},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1506.02640}, 
}

@article{DBLP:journals/corr/KrishnaZGJHKCKL16,
  author       = {Ranjay Krishna and
                  Yuke Zhu and
                  Oliver Groth and
                  Justin Johnson and
                  Kenji Hata and
                  Joshua Kravitz and
                  Stephanie Chen and
                  Yannis Kalantidis and
                  Li{-}Jia Li and
                  David A. Shamma and
                  Michael S. Bernstein and
                  Li Fei{-}Fei},
  title        = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense
                  Image Annotations},
  journal      = {CoRR},
  volume       = {abs/1602.07332},
  year         = {2016},
  url          = {http://arxiv.org/abs/1602.07332},
  eprinttype    = {arXiv},
  eprint       = {1602.07332},
  timestamp    = {Fri, 08 Nov 2024 10:13:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/KrishnaZGJHKCKL16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{book,
author = {Gandon, Fabien and Krummenacher, Reto and Han, Sung-Kook and Toma, Ioan},
year = {2011},
month = {01},
pages = {},
title = {The Resource Description Framework and its Schema}
}

@article{DBLP:journals/corr/OSheaN15,
  author       = {Keiron O'Shea and
                  Ryan Nash},
  title        = {An Introduction to Convolutional Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1511.08458},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.08458},
  eprinttype    = {arXiv},
  eprint       = {1511.08458},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/OSheaN15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/VaswaniSPUJGKP17,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/AntolALMBZP15,
  author       = {Stanislaw Antol and
                  Aishwarya Agrawal and
                  Jiasen Lu and
                  Margaret Mitchell and
                  Dhruv Batra and
                  C. Lawrence Zitnick and
                  Devi Parikh},
  title        = {{VQA:} Visual Question Answering},
  journal      = {CoRR},
  volume       = {abs/1505.00468},
  year         = {2015},
  url          = {http://arxiv.org/abs/1505.00468},
  eprinttype    = {arXiv},
  eprint       = {1505.00468},
  timestamp    = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/AntolALMBZP15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gautam2024kvasirvqa,
  title={Kvasir-VQA: A Text-Image Pair GI Tract Dataset},
  author={Gautam, Sushant and Storås, Andrea and Midoglu, Cise and Hicks, Steven A. and Thambawita, Vajira and Halvorsen, Pål and Riegler, Michael A.},
  booktitle={Proceedings of the First International Workshop on Vision-Language Models for Biomedical Applications (VLM4Bio '24)},
  year={2024},
  location={Melbourne, VIC, Australia},
  pages={10 pages},
  publisher={ACM},
  doi={10.1145/3689096.3689458}
}

@misc{liu2022deplot,
      title={DePlot: One-shot visual language reasoning by plot-to-table translation},
      author={Liu, Fangyu and Eisenschlos, Julian Martin and Piccinno, Francesco and Krichene, Syrine and Pang, Chenxi and Lee, Kenton and Joshi, Mandar and Chen, Wenhu and Collier, Nigel and Altun, Yasemin},
      year={2022},
      eprint={2212.10505},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{simonyan2015vgg,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={International Conference on Learning Representations},
  year={2015},
  url={https://arxiv.org/abs/1409.1556}
}

@article{WU201721,
title = {Visual question answering: A survey of methods and datasets},
journal = {Computer Vision and Image Understanding},
volume = {163},
pages = {21-40},
year = {2017},
note = {Language in Vision},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2017.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1077314217300772},
author = {Qi Wu and Damien Teney and Peng Wang and Chunhua Shen and Anthony Dick and Anton {van den Hengel}},
keywords = {Visual question answering, Natural language processing, Knowledge bases, Recurrent neural networks},
abstract = {Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Given an image and a question in natural language, it requires reasoning over visual elements of the image and general knowledge to infer the correct answer. In the first part of this survey, we examine the state of the art by comparing modern approaches to the problem. We classify methods by their mechanism to connect the visual and textual modalities. In particular, we examine the common approach of combining convolutional and recurrent neural networks to map images and questions to a common feature space. We also discuss memory-augmented and modular architectures that interface with structured knowledge bases. In the second part of this survey, we review the datasets available for training and evaluating VQA systems. The various datatsets contain questions at different levels of complexity, which require different capabilities and types of reasoning. We examine in depth the question/answer pairs from the Visual Genome project, and evaluate the relevance of the structured annotations of images with scene graphs for VQA. Finally, we discuss promising future directions for the field, in particular the connection to structured knowledge bases and the use of natural language processing models.}
}

@InProceedings{Zhu_2016_CVPR,
author = {Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
title = {Visual7W: Grounded Question Answering in Images},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{DBLP:journals/corr/AndreasRDK16,
  author       = {Jacob Andreas and
                  Marcus Rohrbach and
                  Trevor Darrell and
                  Dan Klein},
  title        = {Learning to Compose Neural Networks for Question Answering},
  journal      = {CoRR},
  volume       = {abs/1601.01705},
  year         = {2016},
  url          = {http://arxiv.org/abs/1601.01705},
  eprinttype    = {arXiv},
  eprint       = {1601.01705},
  timestamp    = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/AndreasRDK16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{borgli2020hyperkvasir,
  title={HyperKvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy},
  author={Borgli, Hanna and Thambawita, Vajira and Smedsrud, Pia H and Hicks, Steven and Jha, Debesh and Eskeland, Sigrun L and Riegler, Michael A and Halvorsen, P{\aa}l and Dezfouli, Arash A and Johansen, Dag and others},
  journal={Scientific Data},
  volume={7},
  number={1},
  pages={283},
  year={2020},
  publisher={Nature Publishing Group}
}

@misc{jacobgilpytorchcam,
  title={PyTorch library for CAM methods},
  author={Jacob Gildenblat and contributors},
  year={2021},
  publisher={GitHub},
  howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}

@misc{alsentzer2019publiclyavailableclinicalbert,
      title={Publicly Available Clinical BERT Embeddings}, 
      author={Emily Alsentzer and John R. Murphy and Willie Boag and Wei-Hung Weng and Di Jin and Tristan Naumann and Matthew B. A. McDermott},
      year={2019},
      eprint={1904.03323},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.03323}, 
}

@article{DBLP:journals/corr/SelvarajuDVCPB16,
  author       = {Ramprasaath R. Selvaraju and
                  Abhishek Das and
                  Ramakrishna Vedantam and
                  Michael Cogswell and
                  Devi Parikh and
                  Dhruv Batra},
  title        = {Grad-CAM: Why did you say that? Visual Explanations from Deep Networks
                  via Gradient-based Localization},
  journal      = {CoRR},
  volume       = {abs/1610.02391},
  year         = {2016},
  url          = {http://arxiv.org/abs/1610.02391},
  eprinttype    = {arXiv},
  eprint       = {1610.02391},
  timestamp    = {Mon, 13 Aug 2018 16:46:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SelvarajuDVCPB16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{jha2021kvasir_instrument,
  title={Kvasir-Instrument: Diagnostic and therapeutic tool segmentation dataset in gastrointestinal endoscopy},
  author={Jha, Debesh and Smedsrud, Pia H and Riegler, Michael A and Halvorsen, P{\aa}l and Lange, Tor-Arne and Johansen, Dag and Johansen, Haakon D and de Lange, Thomas and Pogorelov, Konstantin},
  journal={Medical Image Analysis},
  volume={70},
  pages={102002},
  year={2021},
  publisher={Elsevier}
}

@article{DBLP:journals/corr/AndersonHBTJGZ17,
  author       = {Peter Anderson and
                  Xiaodong He and
                  Chris Buehler and
                  Damien Teney and
                  Mark Johnson and
                  Stephen Gould and
                  Lei Zhang},
  title        = {Bottom-Up and Top-Down Attention for Image Captioning and {VQA}},
  journal      = {CoRR},
  volume       = {abs/1707.07998},
  year         = {2017},
  url          = {http://arxiv.org/abs/1707.07998},
  eprinttype    = {arXiv},
  eprint       = {1707.07998},
  timestamp    = {Tue, 21 Feb 2023 13:37:04 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/AndersonHBTJGZ17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@article{DBLP:journals/corr/RedmonDGF15,
  author       = {Joseph Redmon and
                  Santosh Kumar Divvala and
                  Ross B. Girshick and
                  Ali Farhadi},
  title        = {You Only Look Once: Unified, Real-Time Object Detection},
  journal      = {CoRR},
  volume       = {abs/1506.02640},
  year         = {2015},
  url          = {http://arxiv.org/abs/1506.02640},
  eprinttype    = {arXiv},
  eprint       = {1506.02640},
  timestamp    = {Mon, 13 Aug 2018 16:48:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RedmonDGF15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

